# YOLO ONNX Inference with C++

Cháº¡y mÃ´ hÃ¬nh YOLO (ONNX) báº±ng C++ sá»­ dá»¥ng ONNX Runtime vÃ  OpenCV.

---

## ğŸ“¦ ThÆ° má»¥c dá»± Ã¡n
```
odicpp/
â”œâ”€â”€ build/ result.output # ThÆ° má»¥c build
â”œâ”€â”€ model/
â”‚ â””â”€â”€ yolo11n.onnx # MÃ´ hÃ¬nh YOLO xuáº¥t sang ONNX
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ infer.cpp # File chÃ­nh
â”‚ â”œâ”€â”€ func.cpp # Tiá»n xá»­ lÃ½ & háº­u xá»­ lÃ½
â”‚ â””â”€â”€ func.hpp
â”œâ”€â”€ test_data/
â”‚ â””â”€â”€ bus.jpg # áº¢nh test
â””â”€â”€ CMakeLists.txt
```
---

## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t

### 1. Cáº­p nháº­t há»‡ thá»‘ng

```
sudo apt update && sudo apt upgrade -y
```
### 2. CÃ i cÃ´ng cá»¥ build vÃ  thÆ° viá»‡n cáº§n thiáº¿t
```
sudo apt install -y build-essential cmake git pkg-config g++ libopencv-dev
```
### 3. CÃ i Python & cÃ¡c gÃ³i Python (Ä‘á»ƒ export ONNX model)
```
sudo apt install -y python3-pip
pip install numpy onnx onnxruntime ultralytics
```
# Náº¿u báº¡n dÃ¹ng CUDA 11.8:
```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
# Náº¿u CUDA >= 12:
```
pip install torch
```
ğŸ“¥ Táº£i ONNX Runtime cho C++
```
wget https://github.com/microsoft/onnxruntime/releases/download/v1.18.0/onnxruntime-linux-x64-1.18.0.tgz
tar -xzf onnxruntime-linux-x64-1.18.0.tgz
```
ThÆ° má»¥c onnxruntime-linux-x64-1.18.0/ sáº½ chá»©a thÆ° viá»‡n vÃ  headers cho C++

ğŸ—ï¸ Build vÃ  cháº¡y chÆ°Æ¡ng trÃ¬nh
```
mkdir build
cd build
cmake ..
make
./yolo
```
âœ… Káº¿t quáº£
áº¢nh sau khi gáº¯n box: result.jpg //chÆ°a update

Káº¿t quáº£ Ä‘áº§u ra dáº¡ng JSON-like: result.output
